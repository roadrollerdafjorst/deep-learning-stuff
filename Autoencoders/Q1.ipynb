{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data, normalizing and flattening it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading tand Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11385 files belonging to 5 classes.\n",
      "Found 3795 files belonging to 5 classes.\n",
      "Found 3795 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = image_dataset_from_directory(\n",
    "    'data/train/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "val = image_dataset_from_directory(\n",
    "    'data/val/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "test = image_dataset_from_directory(\n",
    "    'data/test/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "def normalize(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train = train.map(normalize)\n",
    "val = val.map(normalize)\n",
    "test = test.map(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing training tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in train:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "train_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing validation tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in val:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "val_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing testing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in test:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "test_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the dimensions to 32, 64, 128 and 256 dimensions through PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = tf.reduce_mean(image_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors[0] -= mean\n",
    "val_vectors[0] -= mean\n",
    "test_vectors[0] -= mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = [32,64,128,256]\n",
    "\n",
    "def get_reduced_representation(dim, vec):\n",
    "    # Calculate the covariance matrix\n",
    "    cov = tf.matmul(vec[0], vec[0], transpose_a=True)# / tf.cast(tf.shape(vec[0])[0], tf.float32)\n",
    "\n",
    "    # Perform eigenvalue decomposition on the covariance matrix\n",
    "    eigenvalues, eigenvectors = tf.linalg.eigh(cov)\n",
    "\n",
    "    # Sort the eigenvectors by eigenvalues in descending order\n",
    "    sorted_idx = tf.argsort(eigenvalues, direction='DESCENDING')\n",
    "    eigenvectors = tf.gather(eigenvectors, sorted_idx, axis=1)\n",
    "\n",
    "    # Keep only the top k eigenvectors\n",
    "    top_k_eigenvectors = tf.slice(eigenvectors, [0, 0], [-1, dim])\n",
    "\n",
    "    # Project the data onto the new basis\n",
    "    reduced_rep = tf.matmul(vec[0], top_k_eigenvectors)\n",
    "    return reduced_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11385,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_reduced_representation(32, train_vectors)\n",
    "train_vectors[1].numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = [\n",
    "    [96, 64, 32],\n",
    "    [64, 96, 128],\n",
    "    [128, 96, 64],\n",
    "    [256, 128, 96]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models with different architectures and optimizers\n",
      "32-96-64-32...\n",
      "epochs: 180, acc: 0.6395257115364075\n",
      "\n",
      "32-64-96-128...\n",
      "epochs: 176, acc: 0.9407992959022522\n",
      "\n",
      "32-128-96-64...\n",
      "epochs: 260, acc: 0.9758453965187073\n",
      "\n",
      "32-256-128-96...\n",
      "epochs: 241, acc: 0.9826086759567261\n",
      "\n",
      "64-96-64-32...\n",
      "epochs: 225, acc: 0.7262187004089355\n",
      "\n",
      "64-64-96-128...\n",
      "epochs: 168, acc: 0.9702239632606506\n",
      "\n",
      "64-128-96-64...\n",
      "epochs: 136, acc: 0.9580149054527283\n",
      "\n",
      "64-256-128-96...\n",
      "epochs: 173, acc: 0.9886692762374878\n",
      "\n",
      "128-96-64-32...\n",
      "epochs: 183, acc: 0.79991215467453\n",
      "\n",
      "128-64-96-128...\n",
      "epochs: 142, acc: 0.9790074825286865\n",
      "\n",
      "128-128-96-64...\n",
      "epochs: 112, acc: 0.8648221492767334\n",
      "\n",
      "128-256-128-96...\n",
      "epochs: 92, acc: 0.9644268751144409\n",
      "\n",
      "256-96-64-32...\n",
      "epochs: 283, acc: 0.9974527955055237\n",
      "\n",
      "256-64-96-128...\n",
      "epochs: 141, acc: 0.9887571334838867\n",
      "\n",
      "256-128-96-64...\n",
      "epochs: 112, acc: 0.9880544543266296\n",
      "\n",
      "256-256-128-96...\n",
      "epochs: 88, acc: 0.9813790321350098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initializer = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=42)\n",
    "\n",
    "model_history = dict()\n",
    "\n",
    "print('Training models with different architectures and optimizers')\n",
    "for reduced_dimension in [32,64,128,256]:\n",
    "    reduced_rep_train = get_reduced_representation(reduced_dimension, train_vectors)\n",
    "    reduced_rep_val = get_reduced_representation(reduced_dimension, val_vectors)\n",
    "    for layer_dims in model_arch:\n",
    "        print(f'{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}...')\n",
    "        # define model\n",
    "        model = Sequential([\n",
    "            layers.Dense(reduced_dimension, activation=\"relu\", input_shape=(reduced_dimension,)),\n",
    "            # keras.Input(input_shape=(reduced_dimension,)),\n",
    "            layers.Dense(layer_dims[0], activation=\"sigmoid\", name=\"layer1\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            layers.Dense(layer_dims[1], activation=\"sigmoid\", name=\"layer2\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            layers.Dense(layer_dims[2], activation=\"sigmoid\", name=\"layer3\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            # layers.Dense(layer_dims[3], activation=\"sigmoid\", name=\"layer4\", \n",
    "            #              kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            layers.Dense(5, activation=\"softmax\", name=\"output\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "        ])\n",
    "        \n",
    "        # compile model\n",
    "        adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "        model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # callbacks\n",
    "        my_callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=10),\n",
    "            TensorBoard(log_dir=f'./logdir/Q1/{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}/')\n",
    "        ]\n",
    "        model_fit = model.fit(reduced_rep_train.numpy(),train_vectors[1].numpy(), batch_size=len(train_vectors[0]), epochs=10000, verbose=0, callbacks=my_callbacks, \n",
    "                              validation_split=0.0, validation_data=(reduced_rep_val.numpy(), val_vectors[1].numpy()), shuffle=True, validation_batch_size=None)\n",
    "        \n",
    "        model_history[f'{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}'] = model_fit.history['accuracy']\n",
    "        \n",
    "        hist_metric = 'accuracy'\n",
    "        print(f'epochs: {len(model_fit.history[hist_metric])}, acc: {model_fit.history[hist_metric][-1]}\\n')\n",
    "        model.save(f'models/Q1/{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}.tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32-96-64-32...\n",
      "356/356 [==============================] - 0s 789us/step - loss: 0.7347 - accuracy: 0.6401\n",
      "119/119 [==============================] - 0s 744us/step - loss: 1.0691 - accuracy: 0.5194\n",
      "119/119 [==============================] - 0s 752us/step - loss: 0.9414 - accuracy: 0.5863\n",
      "\n",
      "\n",
      "\n",
      "32-64-96-128...\n",
      "356/356 [==============================] - 0s 736us/step - loss: 0.2415 - accuracy: 0.9412\n",
      "119/119 [==============================] - 0s 808us/step - loss: 0.7204 - accuracy: 0.7528\n",
      "119/119 [==============================] - 0s 757us/step - loss: 0.5522 - accuracy: 0.8121\n",
      "\n",
      "\n",
      "\n",
      "32-128-96-64...\n",
      "356/356 [==============================] - 0s 739us/step - loss: 0.1117 - accuracy: 0.9763\n",
      "119/119 [==============================] - 0s 757us/step - loss: 0.6638 - accuracy: 0.7974\n",
      "119/119 [==============================] - 0s 786us/step - loss: 0.4447 - accuracy: 0.8556\n",
      "\n",
      "\n",
      "\n",
      "32-256-128-96...\n",
      "356/356 [==============================] - 0s 834us/step - loss: 0.0706 - accuracy: 0.9829\n",
      "119/119 [==============================] - 0s 845us/step - loss: 0.4974 - accuracy: 0.8545\n",
      "119/119 [==============================] - 0s 938us/step - loss: 0.4686 - accuracy: 0.8493\n",
      "\n",
      "\n",
      "\n",
      "64-96-64-32...\n",
      "356/356 [==============================] - 0s 834us/step - loss: 0.6584 - accuracy: 0.7290\n",
      "119/119 [==============================] - 0s 735us/step - loss: 1.0480 - accuracy: 0.5942\n",
      "119/119 [==============================] - 0s 762us/step - loss: 0.9730 - accuracy: 0.6519\n",
      "\n",
      "\n",
      "\n",
      "64-64-96-128...\n",
      "356/356 [==============================] - 0s 750us/step - loss: 0.1599 - accuracy: 0.9705\n",
      "119/119 [==============================] - 0s 755us/step - loss: 0.6274 - accuracy: 0.7852\n",
      "119/119 [==============================] - 0s 744us/step - loss: 0.5316 - accuracy: 0.8121\n",
      "\n",
      "\n",
      "\n",
      "64-128-96-64...\n",
      "356/356 [==============================] - 0s 775us/step - loss: 0.2843 - accuracy: 0.9587\n",
      "119/119 [==============================] - 0s 769us/step - loss: 0.8116 - accuracy: 0.7310\n",
      "119/119 [==============================] - 0s 778us/step - loss: 0.6828 - accuracy: 0.7866\n",
      "\n",
      "\n",
      "\n",
      "64-256-128-96...\n",
      "356/356 [==============================] - 0s 877us/step - loss: 0.0715 - accuracy: 0.9890\n",
      "119/119 [==============================] - 0s 837us/step - loss: 0.7231 - accuracy: 0.7889\n",
      "119/119 [==============================] - 0s 854us/step - loss: 0.5737 - accuracy: 0.8253\n",
      "\n",
      "\n",
      "\n",
      "128-96-64-32...\n",
      "356/356 [==============================] - 0s 739us/step - loss: 0.4650 - accuracy: 0.7999\n",
      "119/119 [==============================] - 0s 762us/step - loss: 1.0398 - accuracy: 0.6466\n",
      "119/119 [==============================] - 0s 771us/step - loss: 0.8151 - accuracy: 0.7170\n",
      "\n",
      "\n",
      "\n",
      "128-64-96-128...\n",
      "356/356 [==============================] - 0s 753us/step - loss: 0.1625 - accuracy: 0.9799\n",
      "119/119 [==============================] - 0s 778us/step - loss: 0.7888 - accuracy: 0.7436\n",
      "119/119 [==============================] - 0s 786us/step - loss: 0.6262 - accuracy: 0.7921\n",
      "\n",
      "\n",
      "\n",
      "128-128-96-64...\n",
      "356/356 [==============================] - 0s 776us/step - loss: 0.4256 - accuracy: 0.8707\n",
      "119/119 [==============================] - 0s 803us/step - loss: 0.8857 - accuracy: 0.6775\n",
      "119/119 [==============================] - 0s 792us/step - loss: 0.9192 - accuracy: 0.6659\n",
      "\n",
      "\n",
      "\n",
      "128-256-128-96...\n",
      "356/356 [==============================] - 1s 1ms/step - loss: 0.2524 - accuracy: 0.9650\n",
      "119/119 [==============================] - 0s 913us/step - loss: 0.7741 - accuracy: 0.7381\n",
      "119/119 [==============================] - 0s 997us/step - loss: 0.7169 - accuracy: 0.7536\n",
      "\n",
      "\n",
      "\n",
      "256-96-64-32...\n",
      "356/356 [==============================] - 0s 857us/step - loss: 0.2058 - accuracy: 0.9975\n",
      "119/119 [==============================] - 0s 972us/step - loss: 0.9178 - accuracy: 0.7373\n",
      "119/119 [==============================] - 0s 879us/step - loss: 0.8350 - accuracy: 0.7499\n",
      "\n",
      "\n",
      "\n",
      "256-64-96-128...\n",
      "356/356 [==============================] - 0s 907us/step - loss: 0.1500 - accuracy: 0.9895\n",
      "119/119 [==============================] - 0s 938us/step - loss: 0.8580 - accuracy: 0.7339\n",
      "119/119 [==============================] - 0s 872us/step - loss: 0.7885 - accuracy: 0.7560\n",
      "\n",
      "\n",
      "\n",
      "256-128-96-64...\n",
      "356/356 [==============================] - 0s 964us/step - loss: 0.2712 - accuracy: 0.9885\n",
      "119/119 [==============================] - 0s 955us/step - loss: 0.8689 - accuracy: 0.7196\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.8080 - accuracy: 0.7468\n",
      "\n",
      "\n",
      "\n",
      "256-256-128-96...\n",
      "356/356 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.9825\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.7855 - accuracy: 0.7431\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.7391 - accuracy: 0.7644\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for reduced_dimension in [32,64,128,256]:\n",
    "    reduced_rep_train = get_reduced_representation(reduced_dimension, train_vectors)\n",
    "    reduced_rep_val = get_reduced_representation(reduced_dimension, val_vectors)\n",
    "    reduced_rep_test = get_reduced_representation(reduced_dimension, test_vectors)\n",
    "    for layer_dims in model_arch:\n",
    "        print(f'{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}...')\n",
    "        temp_model = tf.keras.models.load_model(\n",
    "            f'models/Q1/{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}.tf')\n",
    "        l, acc = temp_model.evaluate(reduced_rep_train.numpy(), train_vectors[1].numpy())\n",
    "        l, acc = temp_model.evaluate(reduced_rep_val.numpy(), val_vectors[1].numpy())\n",
    "        l, acc = temp_model.evaluate(reduced_rep_test.numpy(), test_vectors[1].numpy())\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 668us/step\n",
      "confusion matrix (test):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "best_arch = '128-96-64'\n",
    "best_model = tf.keras.models.load_model(\n",
    "            f'models/Q1/{32}-{best_arch}.tf')\n",
    "\n",
    "test_pred = best_model.predict(get_reduced_representation(32, test_vectors))\n",
    "pred_class_test = np.argmax(test_pred, axis=1)\n",
    "\n",
    "test_score = accuracy_score(test_vectors[1].numpy(), pred_class_test)\n",
    "\n",
    "print('confusion matrix (test):')\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "#fig.suptitle('Confusion Matrix (Test Set)', y=0.04, fontsize=15)\n",
    "ax = fig.add_subplot(111)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(test_vectors[1].numpy(), pred_class_test), display_labels=['0', '1', '5', '7', '8'])\n",
    "cm_display.plot(ax = ax, cmap='Greys', colorbar=False)\n",
    "ax.set_title(f'arch: {best_arch}, acc: {0.8216}', fontdict = {'fontsize':14}, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 1, 4, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
